{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HackOn(Data)\n",
    "## Competition Challenge\n",
    "\n",
    "Welcome to our project. We have decided to do a simple Forecasting on the salesRank, more precesilly, \n",
    "\n",
    "** The problem:** Knowing the first set of reviews of a product forecast the salesRank of it. \n",
    "\n",
    "** Hypothesis:** The reviews are an indicative of how well a product is selling and contain enough information for a forecast.\n",
    "\n",
    "** Assumptions:** \n",
    "\n",
    "- We ommit that the data is seasonal.\n",
    "- By product we mean the combination of product and vendors, that is represented by the asin.\n",
    "- What else?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 - Loading the tools\n",
    "\n",
    "We load the tools we will be using during this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import gzip\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer #To be used with the categories feature\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1- Cleaning and preparing The Data\n",
    "\n",
    "In this section we load the data, clean it, and prepare it for feature building. The data consists on\n",
    "\n",
    "### **Review Data**\n",
    "\n",
    "This dataset contains product reviews and metadata from Amazon, including 142.8 million reviews spanning May 1996 - July 2014.\n",
    "\n",
    "This dataset includes reviews (ratings, text, helpfulness votes), product metadata (descriptions, category information, price, brand, and image features), and links (also viewed/also bought graphs).\n",
    "\n",
    "### **Q&A Data**\n",
    "\n",
    "This dataset contains Questions and Answers data from Amazon, totaling around 1.4 million answered questions.\n",
    "\n",
    "This dataset can be combined with Amazon product review data, by matching ASINs in the Q/A dataset with ASINs in the review data. The review data also includes product metadata (product titles etc.).\n",
    "\n",
    "### **Credits:**\n",
    "\n",
    "-  **R. He, J. McAuley**. Modeling the visual evolution of fashion trends with one-class collaborative filtering. WWW, 2016 J. \n",
    "- ** McAuley, C. Targett, J. Shi, A. van den Hengel **. A Image-based recommendations on styles and substitutes. SIGIR, 2015\n",
    "\n",
    "\n",
    "We start with the scripts provided at [Julian McAuley's website](http://jmcauley.ucsd.edu/data/amazon/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use these methods to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = getDF('./data/reviews_Video_Games_5.json.gz')\n",
    "df_meta=getDF('./data/meta_Video_Games.json.gz')\n",
    "df_qa=getDF('./data/qa_Video_Games.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now study the different features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Features from the meta file\n",
    "\n",
    "### SalesRank\n",
    "\n",
    "Note that the dataframe that contains the salesRank is df_meta. In this data there are two possible cases where the values described are not helpful. The first one is a NaN value, and we can use is null method to deal with this, the second one is the case of a dictionary no containing the relevant key. We use a helper function to help us with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RELEVANT_KEY='Video Games'\n",
    "def helper(dictionary):\n",
    "    try:\n",
    "        return dictionary[RELEVANT_KEY]\n",
    "    except:\n",
    "        return float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta['salesRank']=df_meta.salesRank.map(lambda x: helper(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now count how many entries don't have the desired rank \n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.salesRank[(df_meta.salesRank.isnull())].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and proceed to remove these rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta=df_meta[ df_meta.salesRank.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a sanity check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.salesRank[(df_meta.salesRank.isnull())].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imUrl\n",
    "\n",
    "This features contains the web address to an image. As ee won't be using the images, so we drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta.drop('imUrl',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title and brand\n",
    "\n",
    "From the fact that the percentage of articles with title or brands are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 0.22% of the products have title.\n",
      "Only 0.11% of the products have brand.\n"
     ]
    }
   ],
   "source": [
    "print(\"Only %.2f%% of the products have title.\"%(df_meta.title.count()/df_meta.asin.count()*100))\n",
    "print(\"Only %.2f%% of the products have brand.\"%(df_meta.brand.count()/df_meta.asin.count()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can deduce that this features are not relevant, and so we drop them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta.drop(['title','brand'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price\n",
    "\n",
    "The feature price is definitely relevant for the  forecasting, now note that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.25% of the products have a price.\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% of the products have a price.\"%(df_meta.price.count()*100/df_meta.asin.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as this is a relevant feature we remove the rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta[df_meta.price.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the products have a price.\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% of the products have a price.\"%(df_meta.price.count()*100/df_meta.asin.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39959 products left\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d products left\"%df_meta.asin.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories\n",
    "\n",
    "The categories feature comes as a list of lists, let's first find out how many different categories are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 334 categories\n"
     ]
    }
   ],
   "source": [
    "categories=set()\n",
    "for list_cats in df_meta.categories:\n",
    "    for list_cat in list_cats:\n",
    "        categories=categories.union(set(list_cat))\n",
    "categories=list(categories)\n",
    "print(\"There are %d categories\"%len(categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use these as a categorial variable, first we create a unique list of categories for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper2(list_cats):\n",
    "    cats=set()\n",
    "    for list_cat in list_cats:\n",
    "        cats=cats.union(set(list_cat))\n",
    "    return list(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta['categories']=df_meta.categories.apply(helper2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we use the [MultiLabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) from sklearn to do the encodding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb=MultiLabelBinarizer()\n",
    "mlb.fit(df_meta.categories)\n",
    "categories_df=pd.DataFrame(mlb.transform(df_meta.categories),columns=list(mlb.classes_))\n",
    "df_meta.reset_index(drop=True,inplace=True)\n",
    "df_meta=df_meta.merge(categories_df,left_index =True,right_index =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we drop the categories column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta.drop('categories',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### related and decription\n",
    "\n",
    "(ARE WE USING THIS?, RELATED MAY GIVE NICE INFO, BUT DESCRIPTION SEEMS USELESS)\n",
    "\n",
    "We won't be using this either, so we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta.drop(['related','description'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features from the reviews file\n",
    "\n",
    "### reviewText\n",
    "\n",
    "This feature containing the review will be used for sentiment analysis. We come back to this when building features. For now, we just get rid of the data with empty reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 44 empty reviews.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d empty reviews.\"%df_reviews[df_reviews.reviewText==\"\"].shape[0])\n",
    "df_reviews=df_reviews[df_reviews.reviewText!=\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary\n",
    "\n",
    "We won't be using this feature, so we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews=df_reviews.drop('summary',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewTime\n",
    "\n",
    "This feature is redundant since we have unixReviewTime, so we also get rid of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews=df_reviews.drop('reviewTime',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReviewerName\n",
    "This is also redundant, since we have the reviewerID, we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reviews=df_reviews.drop('reviewerName',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Feature engineering\n",
    "\n",
    "In this part we build our features, this will be done in the following order.\n",
    "\n",
    "\n",
    "- Use sentiment analysis to give a sentiment score to the reviews. (Reason: a score of 3 for two people may mean different things the sentiment wil help correct this)\n",
    "\n",
    "- ReviewerID features: will help us gain confidence in the review.\n",
    "\n",
    "- helpful: Increases the confidence.\n",
    "\n",
    "- ReviewTime: To create a time series for the (cummulative) number of reviews.\n",
    "\n",
    "- Categories: Create category 'Other' and move everything that is not in the top 20 categories to the 'Other' category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis on reviews\n",
    "\n",
    "We use fasttext from facebook [CITE] to create an score. For this we need to save the data we need to a text file, since that is the signature of the training method of fasttext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment=df_reviews.loc[:,('reviewText','overall')]\n",
    "df_sentiment['overall']=df_sentiment.overall.apply(lambda x: '__label__'+str(int(x)))\n",
    "df_sentiment.to_csv(r'./data_/data_for_sentiment.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that the data is prepared for procesing, we can use the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = fasttext.supervised('./data_/data_for_sentiment.txt', 'model', label_prefix='__label__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and do a simple, sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5'], ['1']]\n"
     ]
    }
   ],
   "source": [
    "texts=[\"this is an awesome\",\"this sucks\"]\n",
    "labels = classifier.predict(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can add this feature to the reviews dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['sentiment_score']=df_reviews.reviewText.apply(\n",
    "    lambda x:classifier.predict([x])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
