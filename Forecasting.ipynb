{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HackOn(Data)\n",
    "## Competition Challenge\n",
    "\n",
    "Welcome to our project. We have decided to do a simple Forecasting on the salesRank, more precesilly, \n",
    "\n",
    "** The problem:** Knowing the first set of reviews of a product forecast the salesRank of it. \n",
    "\n",
    "** Hypothesis:** The reviews are an indicative of how well a product is selling and contain enough information for a forecast.\n",
    "\n",
    "** Assumptions:** \n",
    "\n",
    "- We ommit that the data is seasonal.\n",
    "- By product we mean the combination of product and vendors, that is represented by the asin.\n",
    "- What else?\n",
    "\n",
    "** NOTE: ** This notebook is intended to show the overall ideas and, in order to make it easier to read, we have sacrificed speed. In the last section when talking about scalability we dwell into these details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 - Loading the tools\n",
    "\n",
    "We load the tools we will be using during this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import gzip\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer #To be used with the categories feature\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1- Cleaning and preparing The Data\n",
    "\n",
    "In this section we load the data, clean it, and prepare it for feature building. The data consists on\n",
    "\n",
    "### **Review Data**\n",
    "\n",
    "This dataset contains product reviews and metadata from Amazon, including 142.8 million reviews spanning May 1996 - July 2014.\n",
    "\n",
    "This dataset includes reviews (ratings, text, helpfulness votes), product metadata (descriptions, category information, price, brand, and image features), and links (also viewed/also bought graphs).\n",
    "\n",
    "### **Q&A Data**\n",
    "\n",
    "This dataset contains Questions and Answers data from Amazon, totaling around 1.4 million answered questions.\n",
    "\n",
    "This dataset can be combined with Amazon product review data, by matching ASINs in the Q/A dataset with ASINs in the review data. The review data also includes product metadata (product titles etc.).\n",
    "\n",
    "### **Credits:**\n",
    "\n",
    "-  **R. He, J. McAuley**. Modeling the visual evolution of fashion trends with one-class collaborative filtering. WWW, 2016 J. \n",
    "- ** McAuley, C. Targett, J. Shi, A. van den Hengel **. A Image-based recommendations on styles and substitutes. SIGIR, 2015\n",
    "\n",
    "\n",
    "We start with the scripts provided at [Julian McAuley's website](http://jmcauley.ucsd.edu/data/amazon/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use these methods to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = getDF('./data/reviews_Video_Games_5.json.gz')\n",
    "df_meta=getDF('./data/meta_Video_Games.json.gz')\n",
    "df_qa=getDF('./data/qa_Video_Games.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now study the different features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Features from the meta file\n",
    "\n",
    "### SalesRank\n",
    "\n",
    "Note that the dataframe that contains the salesRank is df_meta. In this data there are two possible cases where the values described are not helpful. The first one is a NaN value, and we can use is null method to deal with this, the second one is the case of a dictionary no containing the relevant key. We use a helper function to help us with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RELEVANT_KEY='Video Games'\n",
    "def helper(dictionary):\n",
    "    try:\n",
    "        return dictionary[RELEVANT_KEY]\n",
    "    except:\n",
    "        return float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta['salesRank']=df_meta.salesRank.map(lambda x: helper(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now count how many entries don't have the desired rank \n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.salesRank[(df_meta.salesRank.isnull())].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and proceed to remove these rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta=df_meta[ df_meta.salesRank.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a sanity check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.salesRank[(df_meta.salesRank.isnull())].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imUrl\n",
    "\n",
    "This features contains the web address to an image. As ee won't be using the images, so we drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta.drop('imUrl',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title and brand\n",
    "\n",
    "From the fact that the percentage of articles with title or brands are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 0.22% of the products have title.\n",
      "Only 0.11% of the products have brand.\n"
     ]
    }
   ],
   "source": [
    "print(\"Only %.2f%% of the products have title.\"%(df_meta.title.count()/df_meta.asin.count()*100))\n",
    "print(\"Only %.2f%% of the products have brand.\"%(df_meta.brand.count()/df_meta.asin.count()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can deduce that this features are not relevant, and so we drop them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta.drop(['title','brand'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price\n",
    "\n",
    "The feature price is definitely relevant for the  forecasting, now note that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.25% of the products have a price.\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% of the products have a price.\"%(df_meta.price.count()*100/df_meta.asin.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as this is a relevant feature we remove the rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta[df_meta.price.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the products have a price.\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% of the products have a price.\"%(df_meta.price.count()*100/df_meta.asin.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39959 products left\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d products left\"%df_meta.asin.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories\n",
    "\n",
    "The categories feature comes as a list of lists, let's first find out how many different categories are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 334 categories\n"
     ]
    }
   ],
   "source": [
    "categories=set()\n",
    "for list_cats in df_meta.categories:\n",
    "    for list_cat in list_cats:\n",
    "        categories=categories.union(set(list_cat))\n",
    "categories=list(categories)\n",
    "print(\"There are %d categories\"%len(categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use these as a categorial variable, first we create a unique list of categories for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper2(list_cats):\n",
    "    cats=set()\n",
    "    for list_cat in list_cats:\n",
    "        cats=cats.union(set(list_cat))\n",
    "    return list(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta['categories']=df_meta.categories.apply(helper2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we use the [MultiLabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) from sklearn to do the encodding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb=MultiLabelBinarizer()\n",
    "mlb.fit(df_meta.categories)\n",
    "categories_df=pd.DataFrame(mlb.transform(df_meta.categories),columns=list(mlb.classes_))\n",
    "df_meta.reset_index(drop=True,inplace=True)\n",
    "df_meta=df_meta.merge(categories_df,left_index =True,right_index =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we drop the categories column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta.drop('categories',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### related and decription\n",
    "\n",
    "(ARE WE USING THIS?, RELATED MAY GIVE NICE INFO, BUT DESCRIPTION SEEMS USELESS)\n",
    "\n",
    "We won't be using this either, so we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=df_meta.drop(['related','description'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features from the reviews file\n",
    "\n",
    "### reviewText\n",
    "\n",
    "This feature containing the review will be used for sentiment analysis. We come back to this when building features. For now, we just get rid of the data with empty reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 44 empty reviews.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d empty reviews.\"%df_reviews[df_reviews.reviewText==\"\"].shape[0])\n",
    "df_reviews=df_reviews[df_reviews.reviewText!=\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary\n",
    "\n",
    "We won't be using this feature, so we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews=df_reviews.drop('summary',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewTime\n",
    "\n",
    "This feature is redundant since we have unixReviewTime, so we also get rid of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews=df_reviews.drop('reviewTime',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReviewerName\n",
    "This is also redundant, since we have the reviewerID, we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reviews=df_reviews.drop('reviewerName',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Feature engineering\n",
    "\n",
    "In this part we build our features, this will be done in the following order.\n",
    "\n",
    "\n",
    "- Use sentiment analysis to give a sentiment score to the reviews. (Reason: a score of 3 for two people may mean different things the sentiment wil help correct this)\n",
    "\n",
    "- ReviewerID features: will help us gain confidence in the review.\n",
    "\n",
    "- helpful: Increases the confidence.\n",
    "\n",
    "- ReviewTime: To create a time series for the (cummulative) number of reviews.\n",
    "\n",
    "- Categories: Create category 'Other' and move everything that is not in the top 20 categories to the 'Other' category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis on reviews\n",
    "\n",
    "We use fasttext from facebook [CITE] to create an score. For this we need to save the data we need to a text file, since that is the signature of the training method of fasttext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment=df_reviews.loc[:,('reviewText','overall')]\n",
    "df_sentiment['overall']=df_sentiment.overall.apply(lambda x: '__label__'+str(int(x)))\n",
    "df_sentiment.to_csv(r'./data_/data_for_sentiment.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that the data is prepared for procesing, we can use the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = fasttext.supervised('./data_/data_for_sentiment.txt', 'model', label_prefix='__label__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and do a simple, sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5'], ['1']]\n"
     ]
    }
   ],
   "source": [
    "texts=[\"this is an awesome\",\"this sucks\"]\n",
    "labels = classifier.predict(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can add this feature to the reviews dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['sentimentScore']=df_reviews.reviewText.apply(\n",
    "    lambda x:int(classifier.predict([x])[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as that was our use of the textReview feature we can get rid of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews=df_reviews.drop('reviewText',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful</th>\n",
       "      <th>sentimentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A2HD75EMZR8QLN</td>\n",
       "      <td>1341792000</td>\n",
       "      <td>[8, 12]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A3UR8NLLY1ZHCX</td>\n",
       "      <td>1372550400</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A1INA0F5CWW3J4</td>\n",
       "      <td>1403913600</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A1DLMTOTHQ4AST</td>\n",
       "      <td>1315958400</td>\n",
       "      <td>[7, 10]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A361M14PU2GUEG</td>\n",
       "      <td>1308009600</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall      reviewerID  unixReviewTime  helpful  \\\n",
       "0  0700099867      1.0  A2HD75EMZR8QLN      1341792000  [8, 12]   \n",
       "1  0700099867      4.0  A3UR8NLLY1ZHCX      1372550400   [0, 0]   \n",
       "2  0700099867      1.0  A1INA0F5CWW3J4      1403913600   [0, 0]   \n",
       "3  0700099867      3.0  A1DLMTOTHQ4AST      1315958400  [7, 10]   \n",
       "4  0700099867      4.0  A361M14PU2GUEG      1308009600   [2, 2]   \n",
       "\n",
       "   sentimentScore  \n",
       "0               1  \n",
       "1               3  \n",
       "2               5  \n",
       "3               1  \n",
       "4               5  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReviewerID\n",
    "\n",
    "We want to measure the quality of a review, so far we only have a values for this, the helpful feature. We add a new feature that comes from the reviewerID where we say that a review has better quality the larger the number of reviews the corresponding revierID has. We start by counting frequencies of the reviewerID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value_counts_reviewerID=df_reviews.reviewerID.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add the feature reviewerQuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reviews['reviewerQuality']=df_reviews.reviewerID.apply(lambda x: value_counts_reviewerID[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we won't be using the reviewerID anymore, we get rid of this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reviews=df_reviews.drop('reviewerID',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation\n",
    "\n",
    "Before we continue with the feature generation, we need to agregate the data by product. This will make the features to be a time series, where the time is controled by the UnixReviewTime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_products = df_reviews.groupby('asin').agg(lambda x:(list(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helpful\n",
    "\n",
    "In order to incorporate the helpful score into the product, we create two variables defined below:\n",
    "\n",
    "$$ \\text{helpfulOverall} = \\sum \\text{overall}_i \\cdot \\frac{\\text{helpful}_i[0]}{\\text{helpful}_i[1]} $$ \n",
    "\n",
    "and \n",
    "\n",
    "$$ \\text{helpfulSentiment} = \\sum \\text{sentiment_score}_i \\cdot \\frac{\\text{helpful}_i[0]}{\\text{helpful}_i[1]} $$ \n",
    "where the sums run over the $i$ such that helpful$_i$[1]$\\neq 0$.\n",
    "\n",
    "We need a helper function to incorporate these new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def helper_helpful(A,B):\n",
    "    total=0\n",
    "    for a,b in zip(A,B):\n",
    "        b1,b2=b\n",
    "        if b2!=0:\n",
    "            total+=a*b1/b2\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products['helpfulOverall']=df_products.apply(lambda row: helper_helpful(row['overall'],row['helpful']),axis=1)\n",
    "df_products['helpfulSentiment']=df_products.apply(lambda row: helper_helpful(row['sentimentScore'],row['helpful']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can drop the helpful feature now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products=df_products.drop(['helpful'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewerQuality\n",
    "\n",
    "As we want to introduced an invariant that captures the quality of the review, we can use this in the same way as with helpful to produce two more features.\n",
    "\n",
    "$$ \\text{qualityOverall} = \\sum \\text{overall}_i \\cdot \\text{reviewerQuality}_i $$ \n",
    "\n",
    "and \n",
    "\n",
    "$$ \\text{qualitySentiment} = \\sum \\text{sentiment}_i \\cdot \\text{reviewerQuality}_i $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as before, we need a helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_quality(A,B):\n",
    "    total=0\n",
    "    for a,b in zip(A,B):\n",
    "        total+=a*b\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products['qualityOverall']=df_products.apply(lambda row: helper_quality(row['overall'],row['reviewerQuality']),axis=1)\n",
    "df_products['qualitySentiment']=df_products.apply(lambda row: helper_quality(row['sentimentScore'],row['reviewerQuality']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we are ready to drop more features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_products=df_products.drop(['overall','sentimentScore','reviewerQuality'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMARK:** The reader should note that there is a faster way to compute the last two features, readly starting from the df_reviews dataframe building the individual multiplications and then aggregating. We opted for the (significantly) slower way to make the notebook easier to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The hotness feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpfulOverall</th>\n",
       "      <th>helpfulSentiment</th>\n",
       "      <th>qualityOverall</th>\n",
       "      <th>qualitySentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0700099867</th>\n",
       "      <td>[1341792000, 1372550400, 1403913600, 131595840...</td>\n",
       "      <td>32.431750</td>\n",
       "      <td>35.031750</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050036071</th>\n",
       "      <td>[1334016000, 1258588800, 1396656000, 129755520...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>274.0</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100027950</th>\n",
       "      <td>[1333497600, 1257724800, 1392940800, 123223680...</td>\n",
       "      <td>15.041667</td>\n",
       "      <td>13.291667</td>\n",
       "      <td>576.0</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293000936</th>\n",
       "      <td>[1360886400, 1315180800, 1380672000, 132062400...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>235.0</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8176503290</th>\n",
       "      <td>[1335657600, 1363305600, 1363564800, 132304320...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>178.0</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               unixReviewTime  helpfulOverall  \\\n",
       "asin                                                                            \n",
       "0700099867  [1341792000, 1372550400, 1403913600, 131595840...       32.431750   \n",
       "6050036071  [1334016000, 1258588800, 1396656000, 129755520...       12.000000   \n",
       "7100027950  [1333497600, 1257724800, 1392940800, 123223680...       15.041667   \n",
       "7293000936  [1360886400, 1315180800, 1380672000, 132062400...        5.000000   \n",
       "8176503290  [1335657600, 1363305600, 1363564800, 132304320...        4.000000   \n",
       "\n",
       "            helpfulSentiment  qualityOverall  qualitySentiment  \n",
       "asin                                                            \n",
       "0700099867         35.031750          1212.0              1276  \n",
       "6050036071          8.000000           274.0               216  \n",
       "7100027950         13.291667           576.0               550  \n",
       "7293000936          5.000000           235.0               251  \n",
       "8176503290          6.000000           178.0               206  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
